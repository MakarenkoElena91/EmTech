{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from: https://keras.io/examples/mnist_cnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(image_train, label_train), (image_test, label_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Putting data_format to \n",
    "# channel_first, you say that for every layer your tensor will have this shape: \n",
    "# (batch, channels, height, width), \n",
    "# but for channel_last you gonna have (batch, height, width, channels).\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    image_train = image_train.reshape(image_train.shape[0], 1, img_rows, img_cols)\n",
    "    image_test = image_test.reshape(image_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    image_train = image_train.reshape(image_train.shape[0], img_rows, img_cols, 1)\n",
    "    image_test = image_test.reshape(image_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "image_train = image_train.astype('float32')\n",
    "image_test = image_test.astype('float32')\n",
    "image_train /= 255\n",
    "image_test /= 255\n",
    "print('image_train shape:', image_train.shape)\n",
    "print(image_train.shape[0], 'train samples')\n",
    "print(image_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "label_train = keras.utils.to_categorical(label_train, num_classes)\n",
    "label_test = keras.utils.to_categorical(label_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Uncomment the next line to see how data looks like\n",
    "# print(image_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 276s 5ms/step - loss: 0.2642 - accuracy: 0.9184 - val_loss: 0.0626 - val_accuracy: 0.9804\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 256s 4ms/step - loss: 0.0918 - accuracy: 0.9729 - val_loss: 0.0401 - val_accuracy: 0.9858\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 280s 5ms/step - loss: 0.0681 - accuracy: 0.9807 - val_loss: 0.0338 - val_accuracy: 0.9884\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 289s 5ms/step - loss: 0.0569 - accuracy: 0.9827 - val_loss: 0.0328 - val_accuracy: 0.9885\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 293s 5ms/step - loss: 0.0483 - accuracy: 0.9858 - val_loss: 0.0281 - val_accuracy: 0.9908\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 265s 4ms/step - loss: 0.0429 - accuracy: 0.9872 - val_loss: 0.0337 - val_accuracy: 0.9888\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 240s 4ms/step - loss: 0.0374 - accuracy: 0.9891 - val_loss: 0.0291 - val_accuracy: 0.9906\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 240s 4ms/step - loss: 0.0354 - accuracy: 0.9894 - val_loss: 0.0311 - val_accuracy: 0.9899\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 240s 4ms/step - loss: 0.0327 - accuracy: 0.9897 - val_loss: 0.0260 - val_accuracy: 0.9909\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 240s 4ms/step - loss: 0.0318 - accuracy: 0.9904 - val_loss: 0.0242 - val_accuracy: 0.9915\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 272s 5ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.0267 - val_accuracy: 0.9913\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 283s 5ms/step - loss: 0.0271 - accuracy: 0.9919 - val_loss: 0.0253 - val_accuracy: 0.9909\n",
      "Test loss: 0.0252721424445961\n",
      "Test accuracy: 0.9908999800682068\n"
     ]
    }
   ],
   "source": [
    "model.fit(image_train, label_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(image_test, label_test))\n",
    "# evaluate the model\n",
    "score = model.evaluate(image_test, label_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mnistModel.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
